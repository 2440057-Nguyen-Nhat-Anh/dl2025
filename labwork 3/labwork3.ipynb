{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87998e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    with open(filename, 'r') as file:\n",
    "        next(file)\n",
    "        for line in file:\n",
    "            parts = line.strip().split(',')\n",
    "            x = [float(parts[0]), float(parts[1])]\n",
    "            y = int(parts[2])\n",
    "            x_values.append(x)\n",
    "            y_values.append(y)\n",
    "    return x_values, y_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df49eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def predict_probability(inputs, weights, bias):\n",
    "    z = sum(i * w for i, w in zip(inputs, weights)) + bias\n",
    "    return sigmoid(z)\n",
    "\n",
    "def calculate_loss(data, labels, weights, bias):\n",
    "    total_loss = 0\n",
    "    for inputs, label in zip(data, labels):\n",
    "        prob = predict_probability(inputs, weights, bias)\n",
    "        prob = max(min(prob, 1 - 1e-15), 1e-15)\n",
    "        total_loss += -label * math.log(prob) - (1 - label) * math.log(1 - prob)\n",
    "    return total_loss / len(data)\n",
    "\n",
    "def update_parameters(data, labels, weights, bias, learning_rate):\n",
    "    weight_gradients = [0] * len(weights)\n",
    "    bias_gradient = 0\n",
    "\n",
    "    for inputs, label in zip(data, labels):\n",
    "        prob = predict_probability(inputs, weights, bias)\n",
    "        error = prob - label\n",
    "        for i in range(len(weights)):\n",
    "            weight_gradients[i] += error * inputs[i]\n",
    "        bias_gradient += error\n",
    "\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= learning_rate * weight_gradients[i] / len(data)\n",
    "    bias -= learning_rate * bias_gradient / len(data)\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "def train_model(data, labels, learning_rate=0.1, epochs=1000):\n",
    "    weights = [0] * len(data[0])\n",
    "    bias = 0\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        weights, bias = update_parameters(data, labels, weights, bias, learning_rate)\n",
    "        loss = calculate_loss(data, labels, weights, bias)\n",
    "        losses.append(loss)\n",
    "        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
    "    return weights, bias, losses\n",
    "\n",
    "def predict(data, weights, bias):\n",
    "    return [1 if predict_probability(inputs, weights, bias) >= 0.5 else 0 for inputs in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a90561",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values, y_values = load_data('loan.csv')\n",
    "\n",
    "weights, bias, losses = train_model(x_values, y_values)\n",
    "preds = predict(x_values, weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ece4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(losses)), losses, label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
